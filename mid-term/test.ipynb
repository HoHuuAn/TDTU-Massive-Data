{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installing prerequisites"
      ],
      "metadata": {
        "id": "-moyVnEWvPTB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOc0FvunClit",
        "outputId": "6540189a-be66-4f43-ebe3-429bca9a568b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "data.csv  data.full.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls /content/drive/MyDrive/MMDS\n",
        "!cp /content/drive/MyDrive//MMDS/data.csv .\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\"\n",
        "import findspark as fs\n",
        "fs.init()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive//MMDS/data.full.csv ."
      ],
      "metadata": {
        "id": "Vtx4TcNFsigJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YS4HHhsCQWn"
      },
      "source": [
        "# Task 1: Basket\n",
        "- All members"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ulsbn1M8x71r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05ee5232-ea17-404b-8c76-8f95311d1661"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/baskets.csv': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!rm -r /content/baskets.csv # Remove existing folder if there is one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jWweXXiRCQGF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64ca9dc4-b4d8-48a5-f08b-6fca1964620b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+--------------------------------------+\n",
            "|Member_number|Date      |Basket                                |\n",
            "+-------------+----------+--------------------------------------+\n",
            "|1014         |01/04/2015|canned beer,cookware                  |\n",
            "|1086         |17/11/2015|beef,butter,curd,soda,other vegetables|\n",
            "|1113         |01/07/2014|whole milk,yogurt,newspapers          |\n",
            "|1122         |25/06/2015|root vegetables,frozen vegetables     |\n",
            "|1146         |23/05/2014|yogurt,soda                           |\n",
            "|1192         |27/12/2014|pastry,brown bread                    |\n",
            "|1222         |08/07/2015|canned beer,coffee                    |\n",
            "|1276         |23/11/2015|condensed milk,hard cheese            |\n",
            "|1323         |30/04/2015|whole milk,beef,bottled beer,soups    |\n",
            "|1377         |12/11/2014|yogurt,tea                            |\n",
            "|1390         |09/04/2014|frozen meals,butter                   |\n",
            "|1574         |02/12/2014|frozen fish,bottled beer              |\n",
            "|1604         |02/03/2014|specialty bar,rolls/buns              |\n",
            "|1793         |27/10/2014|brown bread,other vegetables          |\n",
            "|1886         |12/02/2015|canned beer,rolls/buns                |\n",
            "|1924         |09/07/2015|sausage,semi-finished bread           |\n",
            "|2001         |18/10/2014|butter,butter milk                    |\n",
            "|2050         |20/10/2014|rolls/buns,UHT-milk                   |\n",
            "|2158         |23/06/2014|newspapers,pot plants,brown bread     |\n",
            "|2159         |17/07/2015|white bread,ham                       |\n",
            "+-------------+----------+--------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "\n",
        "# Initialize Spark session\n",
        "spark = SparkSession.builder.appName(\"ShoppingBaskets\").getOrCreate()\n",
        "\n",
        "# Load the data.csv file into a DataFrame\n",
        "df = spark.read.csv(\"data.full.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Convert date column to the correct format\n",
        "df = df.withColumn(\"Date\", F.to_date(F.col(\"Date\"), \"dd/MM/yyyy\"))\n",
        "\n",
        "window_spec = Window.partitionBy(\"Member_number\", \"Date\")\n",
        "\n",
        "# Group by Member_number and Date, then collect unique itemDescriptions into a list\n",
        "grouped_df = df.withColumn(\"Basket\", F.concat_ws(',',F.collect_set(\"itemDescription\").over(window_spec)))\n",
        "\n",
        "# Drop duplicates to get unique rows for each customer on each day\n",
        "grouped_df = grouped_df.dropDuplicates([\"Member_number\", \"Date\", \"Basket\"]).select([\"Member_number\", \"Date\", \"Basket\"])\n",
        "\n",
        "# Show the result\n",
        "\n",
        "grouped_df = grouped_df.withColumn(\"Date\", F.date_format(F.col(\"Date\"), \"dd/MM/yyyy\"))\n",
        "\n",
        "# Show the resulting DataFrame\n",
        "grouped_df.show(truncate=False)\n",
        "\n",
        "# Save the result to baskets.csv file with specified separators\n",
        "grouped_df.write.option(\"sep\", \";\") \\\n",
        "                .csv(\"baskets.csv\", header=True)\n",
        "# Stop the Spark session\n",
        "spark.stop()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/baskets.csv/part-00000-5d7aacac-5815-4304-bbb0-dee2d5e21456-c000.csv"
      ],
      "metadata": {
        "id": "ajpjhoSGiSKR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac937616-272e-4331-a44f-edf3b2832a99"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Member_number;Date;Basket\n",
            "1014;01/04/2015;canned beer,cookware\n",
            "1086;17/11/2015;beef,butter,curd,soda,other vegetables\n",
            "1113;01/07/2014;whole milk,yogurt,newspapers\n",
            "1122;25/06/2015;root vegetables,frozen vegetables\n",
            "1146;23/05/2014;yogurt,soda\n",
            "1192;27/12/2014;pastry,brown bread\n",
            "1222;08/07/2015;canned beer,coffee\n",
            "1276;23/11/2015;condensed milk,hard cheese\n",
            "1323;30/04/2015;whole milk,beef,bottled beer,soups\n",
            "1377;12/11/2014;yogurt,tea\n",
            "1390;09/04/2014;frozen meals,butter\n",
            "1574;02/12/2014;frozen fish,bottled beer\n",
            "1604;02/03/2014;specialty bar,rolls/buns\n",
            "1793;27/10/2014;brown bread,other vegetables\n",
            "1886;12/02/2015;canned beer,rolls/buns\n",
            "1924;09/07/2015;sausage,semi-finished bread\n",
            "2001;18/10/2014;butter,butter milk\n",
            "2050;20/10/2014;rolls/buns,UHT-milk\n",
            "2158;23/06/2014;newspapers,pot plants,brown bread\n",
            "2159;17/07/2015;white bread,ham\n",
            "2242;12/01/2014;butter,frozen vegetables\n",
            "2347;15/01/2014;sausage,canned beer\n",
            "2360;07/09/2014;rolls/buns,napkins\n",
            "2400;02/06/2015;whole milk,ice cream,margarine\n",
            "2427;22/12/2014;pip fruit,other vegetables\n",
            "2428;12/06/2014;fruit/vegetable juice,UHT-milk,whipped/sour cream\n",
            "2524;17/10/2015;citrus fruit,frankfurter\n",
            "2540;03/05/2015;sausage,rolls/buns\n",
            "2542;24/11/2015;whole milk,root vegetables,margarine\n",
            "2575;22/02/2015;beef,citrus fruit\n",
            "2580;17/11/2015;pip fruit,newspapers,other vegetables\n",
            "2581;14/12/2015;meat,coffee\n",
            "2706;02/12/2015;specialty chocolate,other vegetables\n",
            "2722;26/07/2014;sweet spreads,root vegetables\n",
            "2746;13/02/2014;curd,dental care\n",
            "2772;08/05/2014;pastry,frozen meals\n",
            "2802;15/12/2014;whole milk,frozen vegetables\n",
            "2840;22/07/2014;yogurt,butter\n",
            "2884;17/03/2014;bottled water,other vegetables\n",
            "2958;14/06/2015;rolls/buns,hamburger meat\n",
            "2975;24/10/2015;cream cheese ,rolls/buns\n",
            "3002;12/12/2014;hygiene articles,seasonal products\n",
            "3036;07/12/2015;chewing gum,sausage,frozen fish,canned beer,yogurt,shopping bags,other vegetables,beverages\n",
            "3045;15/06/2014;turkey,other vegetables\n",
            "3128;30/08/2015;ice cream,bottled beer,brown bread\n",
            "3148;28/03/2015;frankfurter,bottled beer,pot plants,UHT-milk\n",
            "3189;28/10/2014;kitchen towels,rolls/buns\n",
            "3222;16/01/2014;rolls/buns,sliced cheese\n",
            "3266;30/10/2014;rolls/buns,UHT-milk\n",
            "3353;13/04/2015;sausage,yogurt,baking powder\n",
            "3363;29/12/2015;pork,margarine\n",
            "3448;26/09/2014;beef,tea\n",
            "3474;19/01/2014;curd,rolls/buns\n",
            "3500;21/07/2015;misc. beverages,pip fruit\n",
            "3548;06/11/2015;spread cheese,pork\n",
            "3574;13/06/2015;domestic eggs,tropical fruit\n",
            "3602;10/07/2014;butter,margarine\n",
            "3629;22/11/2014;yogurt,rolls/buns\n",
            "3645;12/05/2015;citrus fruit,rolls/buns\n",
            "3743;22/12/2014;pickled vegetables,hard cheese\n",
            "3750;17/05/2015;pastry,curd\n",
            "3755;14/04/2015;hygiene articles,root vegetables\n",
            "3802;06/08/2014;chewing gum,specialty chocolate\n",
            "3824;02/12/2015;whole milk,root vegetables\n",
            "3937;10/02/2014;rolls/buns,soda\n",
            "3947;12/05/2014;cocoa drinks,red/blush wine\n",
            "3962;18/09/2015;sliced cheese,tropical fruit,hamburger meat,coffee,whipped/sour cream\n",
            "4015;17/02/2014;canned beer,bottled beer\n",
            "4018;30/10/2014;specialty bar,bottled water,dental care\n",
            "4045;30/07/2014;waffles,tropical fruit,coffee,whipped/sour cream\n",
            "4069;08/10/2014;pickled vegetables,Instant food products\n",
            "4122;20/10/2014;nut snack,dessert,bottled water\n",
            "4137;25/06/2014;domestic eggs,hamburger meat\n",
            "4233;18/01/2014;chicken,soda,packaged fruit/vegetables\n",
            "4286;09/12/2015;photo/film,other vegetables\n",
            "4344;30/10/2014;softener,margarine\n",
            "4441;12/12/2014;newspapers,fruit/vegetable juice,waffles\n",
            "4537;01/01/2015;brown bread,ham\n",
            "4550;26/03/2015;canned beer,chicken,other vegetables\n",
            "4859;06/07/2014;curd,other vegetables\n",
            "4895;09/07/2015;sausage,domestic eggs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhrdPi2DRSFh"
      },
      "source": [
        "# Abstract class\n",
        "- Tran Nguyen Duy Bao: 521H0493"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5Rjgd9aaPVHE"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql import DataFrame\n",
        "\n",
        "# Initialize Spark session\n",
        "from abc import ABC, abstractmethod\n",
        "\n",
        "class FindRules(ABC):\n",
        "  def __init__(self,path: str, S: float, C: float):\n",
        "    self.spark = SparkSession.builder.appName(\"FindRules\").getOrCreate()\n",
        "    self.sc = self.spark.sparkContext\n",
        "    self.path=path\n",
        "    self.S = S\n",
        "    self.C = C\n",
        "    self.baskets_df = self.read_baskets()\n",
        "    self.item = self.baskets_df.select(explode(self.baskets_df[\"Basket\"]) \\\n",
        "                                    .alias(\"item\"))\n",
        "    self.total_baskets = self.baskets_df.count()\n",
        "\n",
        "  @abstractmethod\n",
        "  def run(self):\n",
        "    pass\n",
        "\n",
        "  def read_baskets(self):\n",
        "    # Read baskets from CSV file\n",
        "    baskets_df = self.spark.read.csv(self.path,\n",
        "                                     header=True,\n",
        "                                     inferSchema=True,\n",
        "                                     sep=';')\n",
        "\n",
        "    baskets_df = baskets_df.withColumn(\"Basket\",\n",
        "                                       F.split(baskets_df[\"Basket\"], \",\"))\n",
        "    return baskets_df\n",
        "\n",
        "  def _save(self, df: DataFrame, destination: str):\n",
        "        df.write.option(\"sep\", \";\").csv(destination, header=True)\n",
        "\n",
        "  def __delete__(self):\n",
        "    self.spark.stop()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBcKwz1KCWBe"
      },
      "source": [
        "# Task 2: A-Priori\n",
        "- Tran Nguyen Duy Bao: 521H0493\n",
        "- Le Tran Nhat Quang: 521H0413"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rJXePfnsCY7E"
      },
      "outputs": [],
      "source": [
        "class APriori(FindRules):\n",
        "    def find_frequent_items(self):\n",
        "        # Count the occurrences of itemsets in the baskets\n",
        "        itemset_counts = self.item.groupBy('item') \\\n",
        "                                            .agg(count('*').alias('count'))\n",
        "        # Calculate support by dividing the count of itemsets by the total number of baskets\n",
        "        support_df = itemset_counts.withColumn('support', itemset_counts['count'] / self.total_baskets)\n",
        "\n",
        "        frequent_items_df = support_df.filter(support_df['support'] >= self.S)\n",
        "\n",
        "        return frequent_items_df\n",
        "\n",
        "    def _generate_pairs(self, frequent_items_df):\n",
        "        # Generate candidate pairs from frequent items\n",
        "        combinations_df = frequent_items_df.crossJoin(frequent_items_df.withColumnRenamed('item', 'item2'))\n",
        "\n",
        "        # Create two separate columns for item1 and item2\n",
        "        pairs = combinations_df \\\n",
        "            .filter(combinations_df[\"item\"] < combinations_df[\"item2\"]) \\\n",
        "            .withColumnRenamed('item', 'item1') \\\n",
        "            .select(\"item1\", \"item2\")\n",
        "        return pairs\n",
        "\n",
        "    def generate_frequent_pairs(self,frequent_items_df):\n",
        "        pairs = self._generate_pairs(frequent_items_df)\n",
        "        basket = self.baskets_df.select('Basket')\n",
        "\n",
        "        tmp_tb = basket.crossJoin(pairs)\n",
        "\n",
        "        frequent_pairs = tmp_tb.filter(array_contains(tmp_tb[\"Basket\"], tmp_tb[\"item1\"]) &\n",
        "                                        array_contains(tmp_tb[\"Basket\"], tmp_tb[\"item2\"])) \\\n",
        "                                .groupBy(tmp_tb[\"item1\"],tmp_tb[\"item2\"]) \\\n",
        "                                .count() \\\n",
        "                                .withColumnRenamed(\"count\", \"freq\") \\\n",
        "                                .selectExpr(\"array(item1, item2) as items\", \"freq\")\n",
        "\n",
        "        return frequent_pairs\n",
        "\n",
        "    def _generate__rule(self, frequent_items_df, frequent_pairs, i,j):\n",
        "      # Calculate support and confidence\n",
        "        assoc_rules_df = frequent_pairs.select(\n",
        "            frequent_pairs['items'][i].alias('antecedent'),\n",
        "            frequent_pairs['items'][j].alias('consequent'),\n",
        "            frequent_pairs['freq']\n",
        "        ).withColumn(\n",
        "            'support',\n",
        "            col('freq') / self.total_baskets\n",
        "        )\n",
        "\n",
        "        # Join assoc_rules_df with frequent_items_df to get support for antecedents\n",
        "        assoc_rules_df = assoc_rules_df.join(\n",
        "            broadcast(frequent_items_df),\n",
        "            on=(assoc_rules_df['antecedent'] == frequent_items_df['item']),\n",
        "            how='inner'\n",
        "        ).select(\n",
        "            'antecedent',\n",
        "            'consequent',\n",
        "            'freq',\n",
        "            assoc_rules_df['support'].alias('support'),\n",
        "            frequent_items_df['support'].alias('antecedent_support')\n",
        "        )\n",
        "\n",
        "        # Calculate confidence\n",
        "        assoc_rules_df = assoc_rules_df.withColumn(\n",
        "            'confidence',\n",
        "            col('support') / col('antecedent_support')\n",
        "        )\n",
        "\n",
        "        assoc_rules_df = assoc_rules_df.drop('antecedent_support', 'freq')\n",
        "\n",
        "        # Convert antecedent and consequent columns to lists of strings\n",
        "        # assoc_rules_df = assoc_rules_df.withColumn(\n",
        "        #     'antecedent',\n",
        "        #     split(col('antecedent'), ', ')\n",
        "        # ).withColumn(\n",
        "        #     'consequent',\n",
        "        #     split(col('consequent'), ', ')\n",
        "        # )\n",
        "\n",
        "        return assoc_rules_df\n",
        "\n",
        "\n",
        "    def generate_association_rules(self, frequent_items_df, frequent_pairs):\n",
        "        assoc_rules_1 = self._generate__rule(frequent_items_df,frequent_pairs,0,1)\n",
        "        assoc_rules_2 = self._generate__rule(frequent_items_df,frequent_pairs,1,0)\n",
        "        unioned_df = assoc_rules_1.union(assoc_rules_2)\n",
        "\n",
        "        return unioned_df.filter(unioned_df.support >= self.S) \\\n",
        "                          .filter(unioned_df.confidence >= self.C)\n",
        "\n",
        "    def run(self):\n",
        "        frequent_items_df = self.find_frequent_items()\n",
        "        frequent_pairs = self.generate_frequent_pairs(frequent_items_df)\n",
        "        association_rules = self.generate_association_rules(frequent_items_df, frequent_pairs)\n",
        "\n",
        "        print('='*15 + 'Apriori' + '='*15)\n",
        "        print(\"Frequent Itemsets:\")\n",
        "        frequent_pairs.show(truncate=False)\n",
        "        print(\"\\nFiltered Association Rules:\")\n",
        "        association_rules = association_rules.orderBy(col(\"antecedent\"), col(\"consequent\"))\n",
        "        association_rules.show(truncate=False)\n",
        "\n",
        "        # Prepare data to save\n",
        "        frequent_pairs = frequent_pairs.withColumn(\"items\",\n",
        "                                      F.concat_ws(\n",
        "                                          \",\", col(\"items\")\n",
        "                                      ))\n",
        "\n",
        "        # save to file\n",
        "        self._save(frequent_pairs,'apriori_frequent_pairs.csv')\n",
        "        self._save(association_rules,'apriori_association_rules.csv')\n",
        "        # frequent_pairs.write.option(\"header\",True) \\\n",
        "        #         .csv('apriori_frequent_pairs.csv')\n",
        "\n",
        "        # association_rules.write.option(\"header\",True) \\\n",
        "        #         .csv('apriori_association_rules.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zbhaq_UUCaMR"
      },
      "source": [
        "# Task 3: PCY\n",
        "- Nguyen Hai Tien Phat: 521H0126\n",
        "- Nguyen Lam Duy: 521H0499\n",
        "- Le Thanh Nhan: 521H0409"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "42od2oD13JBl"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import StructType, StructField, ArrayType, StringType, IntegerType\n",
        "\n",
        "class PCY(APriori):\n",
        "    def __init__(self,path: str, S: float, C: float, bucket_size: int = 1000):\n",
        "        super().__init__(path,S,C)\n",
        "        self.bucket_size = bucket_size\n",
        "\n",
        "    def generate_frequent_pairs(self, frequent_items_df):\n",
        "        pairs = self._generate_pairs(frequent_items_df)\n",
        "        pairs = pairs.withColumn('hash_value', abs(hash(concat_ws('\\t',*pairs.columns)) % self.bucket_size))\n",
        "\n",
        "        hash_df = pairs.select(pairs['hash_value']) \\\n",
        "                      .groupBy(pairs['hash_value']) \\\n",
        "                        .count()\n",
        "\n",
        "        basket = self.baskets_df.select('Basket')\n",
        "\n",
        "\n",
        "        hash_df = hash_df.filter((col(\"count\") / self.total_baskets) >= self.S)\n",
        "        hash_dict = hash_df.rdd.collectAsMap()\n",
        "        if not hash_dict:\n",
        "          schema = StructType([\n",
        "                                  StructField(\"items\", ArrayType(StringType(), True), True),\n",
        "                                  StructField(\"freq\", IntegerType(), True)\n",
        "                              ])\n",
        "          return self.spark.createDataFrame([], schema)\n",
        "        tmp_tb = basket.crossJoin(pairs)\n",
        "\n",
        "        frequent_pairs = tmp_tb.filter(expr('hash_value IN ({})'.format(','.join(map(str, hash_dict))))) \\\n",
        "                                .filter(array_contains(tmp_tb[\"Basket\"], tmp_tb[\"item1\"]) &\n",
        "                                        array_contains(tmp_tb[\"Basket\"], tmp_tb[\"item2\"])) \\\n",
        "                                .groupBy(tmp_tb[\"item1\"], tmp_tb[\"item2\"]) \\\n",
        "                                .count() \\\n",
        "                                .withColumnRenamed(\"count\", \"freq\") \\\n",
        "                                .selectExpr(\"array(item1, item2) as items\", \"freq\")\n",
        "\n",
        "        return frequent_pairs\n",
        "\n",
        "    def run(self):\n",
        "        frequent_items_df = self.find_frequent_items()\n",
        "        frequent_pairs = self.generate_frequent_pairs(frequent_items_df)\n",
        "        association_rules = self.generate_association_rules(frequent_items_df, frequent_pairs)\n",
        "\n",
        "        print('=' * 15 + 'PCY' + '=' * 15)\n",
        "        print(\"Frequent Itemsets:\")\n",
        "        frequent_pairs.show(truncate=False)\n",
        "        print(\"\\nFiltered Association Rules:\")\n",
        "        association_rules = association_rules.orderBy(col(\"antecedent\"), col(\"consequent\"))\n",
        "        association_rules.show(truncate=False)\n",
        "\n",
        "        # Prepare data to save\n",
        "        frequent_pairs = frequent_pairs.withColumn(\"items\",\n",
        "                                                  F.concat_ws(\n",
        "                                                      \",\", col(\"items\")\n",
        "                                                  ))\n",
        "\n",
        "        # save to file\n",
        "        self._save(frequent_pairs, 'pcy_frequent_pairs.csv')\n",
        "        self._save(association_rules, 'pcy_association_rules.csv')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLi_kksmUm2y"
      },
      "source": [
        "# Task 4: FPGrowth\n",
        "- Nguyen Hai Tien Phat: 521H0126"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "FwLlNY5aXAje"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.fpm import FPGrowth as FPG\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "class FPGrowth(FindRules):\n",
        "\n",
        "    def run(self):\n",
        "        fp = FPG(minSupport=self.S, minConfidence=self.C, itemsCol='Basket', predictionCol='prediction')\n",
        "        self.model = fp.fit(self.baskets_df)\n",
        "        self.display_results()\n",
        "\n",
        "    def display_results(self):\n",
        "        print('='*15 + 'FPGrowth' + '='*15)\n",
        "\n",
        "        print(\"Frequent Itemsets:\")\n",
        "        self.model.freqItemsets.filter(size(self.model.freqItemsets.items) == 2) \\\n",
        "                                .show(truncate=False)\n",
        "\n",
        "        print(\"\\nFiltered Association Rules:\")\n",
        "        assoc_rules = self.model.associationRules.filter((size(self.model.associationRules.antecedent) == 1) &\n",
        "                                                        (size(self.model.associationRules.consequent) == 1))\n",
        "        assoc_rules = assoc_rules.withColumn(\"antecedent\", explode(assoc_rules.antecedent)) \\\n",
        "                   .withColumn(\"consequent\", explode(assoc_rules.consequent))\n",
        "        assoc_rules = assoc_rules.orderBy(col(\"antecedent\"), col(\"consequent\"))\n",
        "        assoc_rules.show(truncate=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparision"
      ],
      "metadata": {
        "id": "2UO1BJUidZ3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete all folders if exist:\n",
        "!rm -r /content/apriori_frequent_pairs.csv\n",
        "!rm -r /content/pcy_frequent_pairs.csv\n",
        "!rm -r /content/apriori_association_rules.csv\n",
        "!rm -r /content/pcy_association_rules.csv"
      ],
      "metadata": {
        "id": "aLbVaybLdpT5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3d762a8-9e56-4d2d-bd2d-66b038bfe228"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/apriori_frequent_pairs.csv': No such file or directory\n",
            "rm: cannot remove '/content/pcy_frequent_pairs.csv': No such file or directory\n",
            "rm: cannot remove '/content/apriori_association_rules.csv': No such file or directory\n",
            "rm: cannot remove '/content/pcy_association_rules.csv': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Calculating Apriori algorithm:"
      ],
      "metadata": {
        "id": "wzow-nSUgZqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "apriori = APriori('/content/baskets.csv',S = 2E-4, C = .5)\n",
        "apriori.run()"
      ],
      "metadata": {
        "id": "fjL7fztTgXyd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbbdabfc-2f7d-4ae4-cd6e-1fedc310f4e0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===============Apriori===============\n",
            "Frequent Itemsets:\n",
            "+---------------------------------------+----+\n",
            "|items                                  |freq|\n",
            "+---------------------------------------+----+\n",
            "|[meat, white wine]                     |1   |\n",
            "|[meat, other vegetables]               |32  |\n",
            "|[frankfurter, pudding powder]          |1   |\n",
            "|[frankfurter, waffles]                 |7   |\n",
            "|[canned vegetables, turkey]            |1   |\n",
            "|[cream cheese , white wine]            |2   |\n",
            "|[potato products, specialty bar]       |1   |\n",
            "|[other vegetables, specialty cheese]   |4   |\n",
            "|[beef, meat spreads]                   |2   |\n",
            "|[beef, salt]                           |2   |\n",
            "|[flower soil/fertilizer, soda]         |1   |\n",
            "|[hard cheese, instant coffee]          |1   |\n",
            "|[hard cheese, pip fruit]               |16  |\n",
            "|[roll products, seasonal products]     |2   |\n",
            "|[cocoa drinks, whole milk]             |2   |\n",
            "|[packaged fruit/vegetables, popcorn]   |1   |\n",
            "|[packaged fruit/vegetables, pot plants]|1   |\n",
            "|[packaged fruit/vegetables, pip fruit] |5   |\n",
            "|[onions, prosecco]                     |1   |\n",
            "|[chicken, sparkling wine]              |2   |\n",
            "+---------------------------------------+----+\n",
            "only showing top 20 rows\n",
            "\n",
            "\n",
            "Filtered Association Rules:\n",
            "+--------------+-----------+---------------------+----------+\n",
            "|antecedent    |consequent |support              |confidence|\n",
            "+--------------+-----------+---------------------+----------+\n",
            "|cream cheese  |whole milk |0.0013366303548753592|0.5       |\n",
            "|roll products |hard cheese|2.0049455323130388E-4|0.6       |\n",
            "+--------------+-----------+---------------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Calculating PCY algorithm:"
      ],
      "metadata": {
        "id": "wpgrgo8Bg0qP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pcy = PCY('/content/baskets.csv',S = 2E-4, C = .5)\n",
        "pcy.run()"
      ],
      "metadata": {
        "id": "9rteYZ_ggdVi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "185521bc-fa3e-4f75-bc72-15fecba7ea16"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===============PCY===============\n",
            "Frequent Itemsets:\n",
            "+---------------------------------------+----+\n",
            "|items                                  |freq|\n",
            "+---------------------------------------+----+\n",
            "|[meat, white wine]                     |1   |\n",
            "|[meat, other vegetables]               |32  |\n",
            "|[frankfurter, pudding powder]          |1   |\n",
            "|[frankfurter, waffles]                 |7   |\n",
            "|[canned vegetables, turkey]            |1   |\n",
            "|[cream cheese , white wine]            |2   |\n",
            "|[potato products, specialty bar]       |1   |\n",
            "|[other vegetables, specialty cheese]   |4   |\n",
            "|[beef, meat spreads]                   |2   |\n",
            "|[beef, salt]                           |2   |\n",
            "|[flower soil/fertilizer, soda]         |1   |\n",
            "|[hard cheese, instant coffee]          |1   |\n",
            "|[hard cheese, pip fruit]               |16  |\n",
            "|[roll products, seasonal products]     |2   |\n",
            "|[cocoa drinks, whole milk]             |2   |\n",
            "|[packaged fruit/vegetables, popcorn]   |1   |\n",
            "|[packaged fruit/vegetables, pot plants]|1   |\n",
            "|[packaged fruit/vegetables, pip fruit] |5   |\n",
            "|[onions, prosecco]                     |1   |\n",
            "|[chicken, sparkling wine]              |2   |\n",
            "+---------------------------------------+----+\n",
            "only showing top 20 rows\n",
            "\n",
            "\n",
            "Filtered Association Rules:\n",
            "+--------------+-----------+---------------------+----------+\n",
            "|antecedent    |consequent |support              |confidence|\n",
            "+--------------+-----------+---------------------+----------+\n",
            "|cream cheese  |whole milk |0.0013366303548753592|0.5       |\n",
            "|roll products |hard cheese|2.0049455323130388E-4|0.6       |\n",
            "+--------------+-----------+---------------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Calculating FPGrowth algorithm:"
      ],
      "metadata": {
        "id": "zuaU945Fg13g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fpg = FPGrowth('/content/baskets.csv', S = 2E-4, C = .5)\n",
        "fpg.run()"
      ],
      "metadata": {
        "id": "nxzSJaYjgiDP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9829d805-2dab-4463-9412-d1ea34a236a0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===============FPGrowth===============\n",
            "Frequent Itemsets:\n",
            "+------------------------------------+----+\n",
            "|items                               |freq|\n",
            "+------------------------------------+----+\n",
            "|[meat spreads, sausage]             |5   |\n",
            "|[meat spreads, other vegetables]    |4   |\n",
            "|[meat spreads, domestic eggs]       |3   |\n",
            "|[meat spreads, whipped/sour cream]  |3   |\n",
            "|[meat spreads, whole milk]          |3   |\n",
            "|[spread cheese, beef]               |3   |\n",
            "|[spread cheese, sugar]              |6   |\n",
            "|[spread cheese, sausage]            |8   |\n",
            "|[spread cheese, pip fruit]          |5   |\n",
            "|[spread cheese, specialty chocolate]|3   |\n",
            "|[spread cheese, pork]               |4   |\n",
            "|[spread cheese, rolls/buns]         |8   |\n",
            "|[spread cheese, root vegetables]    |9   |\n",
            "|[spread cheese, specialty bar]      |4   |\n",
            "|[spread cheese, yogurt]             |7   |\n",
            "|[spread cheese, newspapers]         |3   |\n",
            "|[spread cheese, bottled water]      |7   |\n",
            "|[spread cheese, pastry]             |3   |\n",
            "|[spread cheese, onions]             |3   |\n",
            "|[spread cheese, other vegetables]   |11  |\n",
            "+------------------------------------+----+\n",
            "only showing top 20 rows\n",
            "\n",
            "\n",
            "Filtered Association Rules:\n",
            "+--------------+-----------+----------+------------------+---------------------+\n",
            "|antecedent    |consequent |confidence|lift              |support              |\n",
            "+--------------+-----------+----------+------------------+---------------------+\n",
            "|cream cheese  |whole milk |0.5       |3.166102412187897 |0.0013366303548753592|\n",
            "|roll products |hard cheese|0.6       |40.808181818181815|2.0049455323130388E-4|\n",
            "+--------------+-----------+----------+------------------+---------------------+\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}